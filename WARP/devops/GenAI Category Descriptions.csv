Pillar,Category,Caption,Description
Survey Level Group,Survey Level Group,Survey Level Group,"Securing AI workloads requires protecting data, models, and infrastructure throughout the AI lifecycle. A comprehensive AI security program addresses input and output protection, data integrity, access governance, agent boundaries, and regulatory compliance. By implementing controls across these areas, organizations build trustworthy AI systems resilient against emerging threats."
GenAI Security: Architecture,SA:01,SA:01 Prompt and Output Security,"Prompt and output security protects AI systems from manipulation through crafted or hidden instructions that could alter model behavior or expose sensitive information. This approach implements controls that detect prompt injection attacks, enforce content filtering, validate outputs before execution, and isolate runtime environments. By securing input validation, output guardrails, and execution isolation, organizations prevent unauthorized actions, ensure policy-aligned responses, and maintain reliable AI-generated content."
GenAI Security: Architecture,SA:02,SA:02 Data & Model Protection,"Data and model protection safeguards AI data assets, models, and training data against unauthorized access, leakage, tampering, and poisoning throughout their lifecycle. This approach implements encryption, access controls, data lineage tracking, and governance policies from data preparation through model deployment. By securing data boundaries and enforcing classification policies, organizations prevent data leaks, maintain model integrity, and ensure compliance with data protection regulations."
GenAI Security: Architecture,SA:03,SA:03 Access Control and Identity,"Access control and identity governance ensures that only trusted users, services, and applications can interact with AI resources. This approach implements strong authentication, authorization policies, least-privilege access, and centralized identity management using managed identities instead of static credentials. By enforcing conditional access and monitoring AI endpoint usage, organizations prevent unauthorized access and maintain accountability across AI workloads."
GenAI Security: Architecture,SA:04,SA:04 Risk Management and Infrastructure,"Risk management and infrastructure protection identifies AI-specific security risks, maintains asset inventories, secures supply chains, and hardens AI infrastructure. This approach implements threat assessments, vulnerability scanning, dependency verification, and network controls across AI pipelines and deployment environments. By systematically tracking AI assets and validating third-party components, organizations reduce exposure to supply chain attacks, detect emerging threats, and maintain secure AI operations."
GenAI Security: Risk Management and Compliance,RC:01,"RC:01 Governance, Accountability & Compliance Alignment","Governance, accountability, and compliance alignment establishes clear roles, responsibilities, and regulatory frameworks to ensure responsible AI practices across the organization. This approach implements policy hierarchies, ownership models, and compliance mappings that connect AI activities to regulatory requirements. By defining accountability structures and aligning with standards, organizations demonstrate due diligence, enable auditable decision-making, and maintain stakeholder trust."
GenAI Security: Risk Management and Compliance,RC:02,RC:02 Data & AI Asset Governance,"Data and AI asset governance implements controls for data integrity, lineage, and access to safeguard sensitive assets throughout their lifecycle. This approach enforces classification policies, tracks data provenance, and applies access restrictions based on sensitivity levels. By maintaining comprehensive asset inventories and governance workflows, organizations ensure compliance with privacy regulations and prevent unauthorized data exposure."
GenAI Security: Risk Management and Compliance,RC:03,RC:03 Secure AI Engineering & Change Governance,"Secure AI engineering and change governance enforces secure development practices and controlled change management throughout the AI model lifecycle. This approach implements code review standards, testing requirements, approval workflows, and version control for models and pipelines. By embedding security into development processes and managing changes systematically, organizations reduce deployment risks and maintain compliance with security standards."
GenAI Security: Risk Management and Compliance,RC:04,"RC:04 Monitoring, Resilience & Incident Readiness","Monitoring, resilience, and incident readiness provides continuous observability and response capabilities to detect, mitigate, and recover from AI-related risks. This approach implements logging, alerting, anomaly detection, and incident response playbooks specific to AI workloads. By establishing proactive monitoring and tested recovery procedures, organizations ensure operational continuity and regulatory adherence during security events."
GenAI Security: Agents Security,AG:01,AG:01 AI Agents Data Security,"AI agents data security ensures agents only access the data they are authorized to use through strong scoping, labeling, and access controls. This approach implements data boundaries, classification enforcement, and runtime access validation for agent interactions. By restricting data exposure to task-specific needs and enforcing least-privilege principles, organizations prevent unauthorized data access and maintain confidentiality across agent operations."
GenAI Security: Agents Security,AG:02,AG:02 AI Agents Identity and Lifecycle Governance,"AI agents identity and lifecycle governance manages how agent identities, credentials, roles, and policies are created, governed, rotated, and retired. This approach implements identity provisioning, credential management, role-based permissions, and decommissioning workflows for agent lifecycles. By maintaining centralized identity controls and enforcing policy consistency, organizations ensure accountability and prevent credential misuse across autonomous agents."
GenAI Security: Agents Security,AG:03,AG:03 AI Agents Threat Protection,"AI agents threat protection defends agents against attack vectors such as prompt injection, tool misuse, memory manipulation, and hallucination-driven actions. This approach implements input validation, tool authorization controls, memory integrity checks, and output verification for agent behaviors. By layering defensive controls across agent execution paths, organizations detect malicious inputs, prevent unauthorized tool invocations, and contain compromised agent activities."
GenAI Security: Agents Security,AG:04,AG:04 AI Agents Responsible AI,"AI agents responsible AI provides transparency, human-in-the-loop safeguards, auditability, and review workflows for safe and accountable agent behavior. This approach implements decision logging, escalation triggers, approval gates, and explainability mechanisms for autonomous actions. By embedding oversight controls and audit trails into agent operations, organizations maintain human accountability, enable post-hoc review, and ensure ethical AI deployment."
